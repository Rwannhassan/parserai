{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c282161f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: urlextract in c:\\users\\m-s\\anaconda3\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: uritools in c:\\users\\m-s\\anaconda3\\lib\\site-packages (from urlextract) (4.0.1)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\m-s\\anaconda3\\lib\\site-packages (from urlextract) (2.5.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\m-s\\anaconda3\\lib\\site-packages (from urlextract) (3.6.0)\n",
      "Requirement already satisfied: idna in c:\\users\\m-s\\anaconda3\\lib\\site-packages (from urlextract) (3.3)\n",
      "Requirement already satisfied: tika in c:\\users\\m-s\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\m-s\\anaconda3\\lib\\site-packages (from tika) (2.28.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\m-s\\anaconda3\\lib\\site-packages (from tika) (63.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\m-s\\anaconda3\\lib\\site-packages (from requests->tika) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\m-s\\anaconda3\\lib\\site-packages (from requests->tika) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\m-s\\anaconda3\\lib\\site-packages (from requests->tika) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\m-s\\anaconda3\\lib\\site-packages (from requests->tika) (2.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install urlextract\n",
    "!pip install tika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25efda44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from tika import parser\n",
    "from urlextract import URLExtract\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb99730c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\M-S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\M-S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\M-S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\M-S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\M-S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package names to\n",
      "[nltk_data]     C:\\Users\\M-S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\M-S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\M-S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import names, stopwords\n",
    "import spacy\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('names')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "\n",
    "# load pre-trained model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "# Grad all general stop words\n",
    "STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "fa558c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Badr Helal\n",
      "\n",
      "GENERAL INFO\n",
      "\n",
      "Full Name: Badr Helal\n",
      "Date of Birth: 1st of July 2000\n",
      "Nationality: Egypt\n",
      "Marital Status: Single\n",
      "Location: New Cairo, Cairo, Egypt\n",
      "\n",
      "CONTACT INFO\n",
      "\n",
      "Mobile: +201553060232\n",
      "Email: baderhelal567@gmail.com\n",
      "Linkedin: https://www.linkedin.com/in/badr-helal-7308111a9/\n",
      "Website: https://www.tridmark.com\n",
      "Github: https://github.com/badr1002\n",
      "\n",
      "PROFESSIONAL EXPERIENCE\n",
      "\n",
      "Jan 2023 to Present\n",
      "(3 months)\n",
      "\n",
      "Full Stack Developer at Anyware Software\n",
      "Cairo, Egypt\n",
      "Industry: Information Technology Services. Company Size: 1-10 employees\n",
      "Working on many projects such as web applications and mobile applications using\n",
      "Node, React, React native and aws services\n",
      "\n",
      "Sep 2021 to Sep 2022\n",
      "(1 year)\n",
      "\n",
      "Mean Stack Developer at E-file\n",
      "Cairo, Egypt\n",
      "Industry: Computer Software. Company Size: 51-100 employees\n",
      "Working on an ECM project using MEAN Stack Development skills and\n",
      "microservices technology.\n",
      "\n",
      "Jul 2021 to Aug 2021\n",
      "(1 month)\n",
      "\n",
      "Mean Stack Developer (intern) at NTI\n",
      "Cairo, Egypt\n",
      "Industry: Computer Software. Company Size: 11-50 employees\n",
      "I have been trained to review the basics of Node, Sorting Data with JSON, restful\n",
      "Apis, working with MongoDB,\n",
      "API Authentication and Security, File Uploads, Emails, Sorting,\n",
      "Pagination,Filtering, Testing,\n",
      "learn the basics of TypeScript, working with Angular framework.\n",
      "\n",
      "Jan 2021 to Mar 2021\n",
      "(1 month)\n",
      "\n",
      "Full Stack Web Developer (intern) at Udacity\n",
      "Cairo, Egypt\n",
      "Industry: Computer Software. Company Size: More than 1000 employees\n",
      "The goal of the Full Stack Web Developer Nanodegree program is to equip learners\n",
      "with the unique skills they need to\n",
      "build and develop a variety of websites and applications using HTML, CSS,\n",
      "JavaScript(ES6), Node.js, Flask and Postgresql.\n",
      "Work to produce complete projects full stack.\n",
      "\n",
      "EDUCATION\n",
      "\n",
      "2018 - 2022 Bachelor’s Degree in computer science\n",
      "El Shorouk Academy (SHA), Egypt\n",
      "Overall Grade: Good\n",
      "Studied Subjects: Program Languages and Skills in Programing Field.\n",
      "\n",
      "1\n",
      "CV produced by WUZZUF on 8th of Apr 2023\n",
      "\n",
      "\n",
      "\n",
      "2020 - 2020 Technical Diploma in Web development\n",
      "Udacity, Egypt\n",
      "Overall Grade: Good\n",
      "Studied Subjects: html,css,js,es6,noode,express,restful api,git,git hup,sql,python\n",
      "and algorithms\n",
      "\n",
      "ACHIEVEMENTS\n",
      "\n",
      "https://www.tridmark.com.\n",
      "\n",
      "CERTIFICATES AND TRAININGS\n",
      "\n",
      "Jul 2021 MEAN Stack development (Score: 98 out of 100)\n",
      "Web Development using Node JS and Angular\n",
      "\n",
      "Feb 2021 React.js (Score: 99 out of 100)\n",
      "\n",
      "Nov 2020 Modern JavaScript ES6 from\n",
      "Modern JavaScript: ES6 and beyond\n",
      "promises, async, await, fetch, get, post, classes, modules and express\n",
      "\n",
      "Nov 2020 SQL (Score: 99 out of 100)\n",
      "\n",
      "Oct 2020 Web Page Development (Score: 87 out of 100)\n",
      "\n",
      "Oct 2020 Java-script advanced (Score: 95 out of 100)\n",
      "\n",
      "Oct 2020 Front End Developer (Score: 99 out of 100)\n",
      "\n",
      "Oct 2020 Web Page Development at Alison\n",
      "Module 1: HTML Coding - Create Web pages\n",
      "Module 2: Cascading Style Sheets - Style Web Pages\n",
      "Module 3: Adobe Dreamweaver CS3 - Create Web Pages and Web Sites\n",
      "Module 4: Assessment\n",
      "\n",
      "Oct 2020 Java-script advanced at Alison\n",
      "Module 1: Writing your First JavaScript Application\n",
      "Module 2: JavaScript Programming Concepts\n",
      "Module 3: Course assessment\n",
      "\n",
      "Oct 2020 web development (Score: 99 out of 100)\n",
      "\n",
      "Jun 2020 React.js at Code With Mosh\n",
      "Learning React Components Hooks router redux api\n",
      "\n",
      "Feb 2020 Web Development Professional (Score: 95 out of 100)\n",
      "\n",
      "LANGUAGES\n",
      "\n",
      "• English: Advanced.\n",
      "\n",
      "SKILLS\n",
      "\n",
      "• Intermediate in Node.js, SQL, RESTful APIs, Angular, Typescript, Back-End Development, Full Stack\n",
      "Development, HTTP, APIs, Computer Skills, HTML, Bootstrap, Object-Oriented Programming, React,\n",
      "Front-end, Front End, MongoDB and JavaScript.\n",
      "\n",
      "2\n",
      "CV produced by WUZZUF on 8th of Apr 2023\n",
      "\n",
      "\n",
      "\n",
      "• Beginner in Git, Google cloud, JSON, Firebase, Express, CSS, ECMAScript (ES6), React, React Native and Web\n",
      "Development.\n",
      "\n",
      "3\n",
      "CV produced by WUZZUF on 8th of Apr 2023\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file = 'badr_helal.cv.pdf'\n",
    "file_data = parser.from_file(file)\n",
    "text = file_data['content']\n",
    "print(text)\n",
    "parsed_content = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "faf7ddbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Badr Helal\n"
     ]
    }
   ],
   "source": [
    "#NAME\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "def extract_name(text):\n",
    "   nlp_text = nlp(text)\n",
    "  \n",
    "   # First name and Last name are always Proper Nouns\n",
    "   pattern = [{'POS': 'PROPN'}, {'POS': 'PROPN'}]\n",
    "  \n",
    "   matcher.add('NAME', [pattern], on_match = None)\n",
    "  \n",
    "   matches = matcher(nlp_text)\n",
    "  \n",
    "   for match_id, start, end in matches:\n",
    "       span = nlp_text[start:end]\n",
    "       return span.text\n",
    "\n",
    "name = extract_name(text)\n",
    "print(name)\n",
    "parsed_content['Name'] =  name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "8181b30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baderhelal567@gmail.com\n"
     ]
    }
   ],
   "source": [
    "#Email\n",
    "import re\n",
    "def get_email_addresses(string):\n",
    "    r = re.compile(r'[\\w\\.-]+@[\\w\\.-]+')\n",
    "    matches = r.findall(string)\n",
    "    if matches:\n",
    "   \n",
    "        return matches[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "email = get_email_addresses(text)\n",
    "print(email)\n",
    "parsed_content['E-mail'] = email "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "89882ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201553060232\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def get_phone_number(string):\n",
    "    r = re.compile(r'(\\d{3}[-.\\s]??\\d{4}[-.\\s]??\\d{4}|\\d{2}\\)\\s*\\d{10}|\\(\\d{3}\\)\\s*\\d{3}[-.\\s]??\\d{4}|\\+\\d{12}|\\(\\d{3}\\) · \\d{3} · \\d{4}|\\(\\d{3}\\) \\d{3}-\\d{4})')\n",
    "    phone_numbers = r.findall(string)\n",
    "    if phone_numbers:\n",
    "        return re.sub(r'\\D', '', phone_numbers[0])\n",
    "\n",
    "phone_number = get_phone_number(text)\n",
    "if phone_number:\n",
    "    print(phone_number)\n",
    "    parsed_content['Phone number'] = phone_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "8bf3592e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Title: Full Stack Developer\n"
     ]
    }
   ],
   "source": [
    "#jobtitle\n",
    "\n",
    "import re\n",
    "\n",
    "job_title_keywords = [\"Information Security Analyst\",\"Cloud Architect\", \"IT Manager\", \"Technical Specialist\",\"deep learning developer\", \"engineer\", \"Data Analyst\",\"FRESHER SOFTWARE DEVELOPE\",\"Customer Service Representative\", \"analyst\",\"Soccer Assistant Coach\", \"Artificial intelligence developer\",\"Computer Scientist\",\"PROGRAMMER\", \"IT Professional\", \"UX Designer & UI Developer\", \"SQL Developer\",\"Sales and Service Specialist\", \"Web Designer\", \"Web Developer\", \"Help Desk Worker/Desktop Support\", \"Software Engineer\",\"Customer Service Representative\", \"Data Entry\", \"DevOps Engineer\", \"Computer Programmer\", \"Network Administrator\", \"IOS developer\",\"Data Scientist\",\"Full Stack developer\",\"Full stack web development\",\"Information Security Analyst\", \"Artificial Intelligence Engineer\",  \"Application Developer\"]\n",
    "\n",
    "# Define a regular expression pattern to match job titles\n",
    "# This example pattern looks for any word in the job_title_keywords list\n",
    "job_title_pattern = r\"(?i)\\b(\" + \"|\".join(job_title_keywords) + r\")\\b\"\n",
    "\n",
    "# Function to extract job title from resume text\n",
    "def extract_job_title(text):\n",
    "    match = re.search(job_title_pattern,text)\n",
    "    if match:\n",
    "        job_title = match.group(1)\n",
    "        return job_title\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Call the function to extract job title from the resume text\n",
    "job_title = extract_job_title(text)\n",
    "if job_title:\n",
    "    parsed_content['Job Title'] = job_title\n",
    "    print(\"Job Title:\", job_title)\n",
    "else:\n",
    "    print(\"No job title found in the resume text.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "a6e92a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Cairo\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def get_address(string):\n",
    "    r = re.compile(r'(?:Alexandria|Giza|Luxor|Aswan|Port Said|Suez|Tanta|Minya|Assiut|Zagazig|Damietta|Faiyum|Qena|Beni Suef|New Cairo|Ismalia|New Cairo|Brooklyn|Banglore|London|El Shorouk|CAIRO|Sohag|Hurghada|Cairo|Damanhur|Damietta|El Arish|El-Mahalla El-Kubra|344 ELM STREET MADISON|El-Tor|Faiyum|Giza|Hurghada|Ismailia|Kafr El Sheikh|Luxor|Mansoura|Marsa Alam|Minya|New Cairo|Port Said|Qena|Columbus, Ohio 44444|Sharm El Sheikh|1209 Page Street No. 7 San Francisco|Sohag|Suez|Tanta|Zagazig)\\b')\n",
    "    matches = r.findall(string)\n",
    "    if matches:\n",
    "        return matches[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "address = get_address(text)\n",
    "print(address)\n",
    "parsed_content['Address'] = address\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "a930635c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st of July 2000\n"
     ]
    }
   ],
   "source": [
    "#birthday\n",
    "import re\n",
    "\n",
    "def get_birthday(string):\n",
    "   \n",
    "    r = re.compile(r'\\b\\d{1,2}(?:st|nd|rd|th)?\\s+of\\s+(?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|Jun(?:e)?|Jul(?:y)?|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember))\\s+\\d{4}|\\d{2}/\\d{2}/\\d{4}\\b')\n",
    "    matches = r.findall(string)\n",
    "    if matches:\n",
    "   \n",
    "        return matches[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "birthday = get_birthday(text)\n",
    "print(birthday)\n",
    "parsed_content['Birthday'] = birthday\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "9724a976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://github.com/badr1002']"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def get_github_link(string):\n",
    "    # Define regular expression pattern to match a Github link\n",
    "    r = re.compile(r'(?:https?://)?(?:www\\.)?github\\.com/(?:[a-zA-Z0-9._-]+/?)*')\n",
    "    matches = r.findall(string)\n",
    "    if matches:\n",
    "        # Return the first match found\n",
    "        return matches\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "parsed_content['Github Link'] = get_github_link(text)\n",
    "parsed_content['Github Link'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "06fc96d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['linkedin.com/in/badr-helal-7308111a9/']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "LINKEDIN_URL_REGEX = r'(linkedin.com/in/\\S+)'\n",
    "\n",
    "def extract_linkedin(text):\n",
    "    urls = re.findall(LINKEDIN_URL_REGEX, text.lower())\n",
    "    if urls:\n",
    "        return list(set(urls))\n",
    "    return None\n",
    "\n",
    "parsed_content['linkedin'] = extract_linkedin(text)\n",
    "print(parsed_content['linkedin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "38332c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "#facebook_link\n",
    "import re\n",
    "\n",
    "def get_facebook_link(string):\n",
    "    # Define regular expression pattern to match a Facebook profile link\n",
    "    r = re.compile(r'(?:https?://)?(?:www\\.)?facebook\\.com/(?:[a-zA-Z0-9._-]+/?)*')\n",
    "    matches = r.findall(string)\n",
    "    if matches:\n",
    "        # Return the first match found\n",
    "        return matches[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "facebook_link = get_facebook_link(text)\n",
    "print(facebook_link)\n",
    "parsed_content['Facebook Link'] = facebook_link\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "40b939c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Flask',\n",
       " 'Writing',\n",
       " 'computer science',\n",
       " 'HTML',\n",
       " 'algorithms',\n",
       " 'SQL',\n",
       " 'html',\n",
       " 'JS',\n",
       " 'JavaScript',\n",
       " 'Postgresql',\n",
       " 'Website',\n",
       " 'Technical',\n",
       " 'api',\n",
       " 'sql',\n",
       " 'Apis',\n",
       " 'css',\n",
       " 'cloud',\n",
       " 'Github',\n",
       " 'Adobe',\n",
       " 'mobile',\n",
       " 'Coding',\n",
       " 'Security',\n",
       " 'Mobile',\n",
       " 'Programming',\n",
       " 'English',\n",
       " 'JSON',\n",
       " 'Computer Software',\n",
       " 'API',\n",
       " 'Testing',\n",
       " 'python',\n",
       " 'js',\n",
       " 'CSS',\n",
       " 'Information Technology',\n",
       " 'aws',\n",
       " 'Email',\n",
       " 'APIs']"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you may read the database from a csv file or some other database\n",
    "# skill extracted from job describtion\n",
    "SKILLS_DB = pd.read_csv(\"skills.csv\") \n",
    "\n",
    "def extract_skills(string):\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "    word_tokens = nltk.tokenize.word_tokenize(string)\n",
    "\n",
    "    # remove the stop words and remove the punctuation\n",
    "    filtered_tokens = [token for token in word_tokens if token not in stop_words and token.isalpha()]\n",
    "\n",
    "    # generate bigrams and trigrams (such as machine learning)\n",
    "    bigrams_trigrams = list(\n",
    "        map(' '.join, nltk.everygrams(filtered_tokens, 2, 3))\n",
    "    )\n",
    "\n",
    "    # we create a set to keep the results in.\n",
    "    found_skills = set()\n",
    "\n",
    "    # we search for each token in our skills database\n",
    "    for token in filtered_tokens:\n",
    "        if token.lower() in SKILLS_DB:\n",
    "            #print(token)\n",
    "            found_skills.add(token)\n",
    "\n",
    "    # we search for each bigram and trigram in our skills database\n",
    "    for ngram in bigrams_trigrams:\n",
    "        if ngram.lower() in SKILLS_DB:\n",
    "            #print(ngram)\n",
    "            found_skills.add(ngram)\n",
    "\n",
    "    return list(found_skills)\n",
    "\n",
    "parsed_content['skills'] = extract_skills(text)\n",
    "parsed_content['skills']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ca5f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######still work in experience and education because it not accurate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "0fd5a1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Year/Date: 2018\n",
      "End Year/Date: 2022\n",
      "Degree: Bachelor’s Degree in computer science\n",
      "University: El Shorouk Academy (SHA), Egypt\n",
      "Grade: Good\n",
      "Studied Subjects: Program Languages and Skills in Programing Field.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Define regular expression pattern for extracting education details\n",
    "education_regex = r'((\\d{4})\\s*-\\s*(\\d{4})\\s*(.+)\\n(.+)\\nOverall Grade: (.+)\\nStudied Subjects: (.+)|(\\d{2}/\\d{4})\\s+to\\s+(\\d{2}/\\d{4})\\s+(.+)\\s+at\\s+(.+))'\n",
    "\n",
    "# Extract education details from the resume text\n",
    "matches = re.findall(education_regex, text)\n",
    "if matches:\n",
    "    education = {}\n",
    "    \n",
    "    # Extract education details from the first pattern\n",
    "    if matches[0][1]:\n",
    "        education['Start Year'] = matches[0][1]\n",
    "        education['End Year'] = matches[0][2]\n",
    "        education['Degree'] = matches[0][3].strip()\n",
    "        education['University'] = matches[0][4].strip()\n",
    "        education['Grade'] = matches[0][5].strip()\n",
    "        education['Studied Subjects'] = matches[0][6].strip()\n",
    "    \n",
    "    # Extract education details from the second pattern\n",
    "    elif matches[0][7]:\n",
    "        education['Start Date'] = matches[0][7]\n",
    "        education['End Date'] = matches[0][8]\n",
    "        education['Degree'] = matches[0][9].strip()\n",
    "        education['University'] = matches[0][10].strip()\n",
    "    \n",
    "    # Print the extracted education details\n",
    "    print(\"Start Year/Date:\", education.get('Start Year', education.get('Start Date')))\n",
    "    print(\"End Year/Date:\", education.get('End Year', education.get('End Date')))\n",
    "    print(\"Degree:\", education['Degree'])\n",
    "    print(\"University:\", education['University'])\n",
    "    if 'Grade' in education:\n",
    "        print(\"Grade:\", education['Grade'])\n",
    "    if 'Studied Subjects' in education:\n",
    "        print(\"Studied Subjects:\", education['Studied Subjects'])\n",
    "    \n",
    "    # Update parsed_content dictionary with education details\n",
    "    parsed_content['Education'] = education\n",
    "    \n",
    "else:\n",
    "    print(\"No education details found in the resume text.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "5673ec34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jan 2023 to Present \n",
      " ( 3 months ) \n",
      "\n",
      " Full Stack Developer at Anyware Software \n",
      " Cairo , Egypt \n",
      " Industry : Information Technology Services . Company Size : 1 - 10 employees \n",
      " Working on many projects such as web applications and mobile applications using \n",
      " Node , React , React native and aws services \n",
      "\n",
      " Sep 2021 to Sep 2022 \n",
      " ( 1 year ) \n",
      "\n",
      " Mean Stack Developer at E - file \n",
      " Cairo , Egypt \n",
      " Industry : Computer Software . Company Size : 51 - 100 employees \n",
      " Working on an ECM project using MEAN Stack Development skills and \n",
      " microservices technology . \n",
      "\n",
      " Jul 2021 to Aug 2021 \n",
      " ( 1 month ) \n",
      "\n",
      " Mean Stack Developer ( intern ) at NTI \n",
      " Cairo , Egypt \n",
      " Industry : Computer Software . Company Size : 11 - 50 employees \n",
      " I have been trained to review the basics of Node , Sorting Data with JSON , restful \n",
      " Apis , working with MongoDB , \n",
      " API Authentication and Security , File Uploads , Emails , Sorting , \n",
      " Pagination , Filtering , Testing , \n",
      " learn the basics of TypeScript , working with Angular framework . \n",
      "\n",
      " Jan 2021 to Mar 2021 \n",
      " ( 1 month ) \n",
      "\n",
      " Full Stack Web Developer ( intern ) at Udacity \n",
      " Cairo , Egypt \n",
      " Industry : Computer Software . Company Size : More than 1000 employees \n",
      " The goal of the Full Stack Web Developer Nanodegree program is to equip learners \n",
      " with the unique skills they need to \n",
      " build and develop a variety of websites and applications using HTML , CSS , \n",
      " JavaScript(ES6 ) , Node.js , Flask and Postgresql . \n",
      " Work to produce complete projects full stack .\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def extract_keywords(text, keywords, stop_words):\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    extracted_keywords = []\n",
    "    stop_words = [word.lower() for word in stop_words]\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        keyword_idx = -1\n",
    "        \n",
    "        for i, token in enumerate(doc):\n",
    "            if token.text.lower() == keyword:\n",
    "                keyword_idx = i\n",
    "                break\n",
    "        \n",
    "        if keyword_idx != -1:\n",
    "            keyword_tokens = []\n",
    "            for token in doc[keyword_idx + 1:]:\n",
    "                if token.text.lower() in stop_words:\n",
    "                    break\n",
    "                keyword_tokens.append(token)\n",
    "            \n",
    "            if keyword_tokens:\n",
    "                keyword_text = ' '.join([token.text for token in keyword_tokens])\n",
    "                extracted_keywords.append(keyword_text.strip())\n",
    "    \n",
    "    return extracted_keywords\n",
    "\n",
    "keywords = [\"experience\",\"experiences\", \"WORK EXPERIENCE\",\"Work history\"]\n",
    "stop_words = [\"EDUCATION\", \"ACHIEVEMENTS\", \"LANGUAGES\", \"Education\", \"Personal\", \"Highlights\"]\n",
    "\n",
    "extracted_keywords = extract_keywords(text, keywords, stop_words)\n",
    "if extracted_keywords:\n",
    "    for keyword in extracted_keywords:\n",
    "        print(keyword)\n",
    "else:\n",
    "    print(\"No relevant keywords found.\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4afda6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "51789eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Name': 'Badr Helal', 'E-mail': 'baderhelal567@gmail.com', 'Phone number': '201553060232', 'Job Title': 'Full Stack Developer', 'Address': 'New Cairo', 'Birthday': '1st of July 2000', 'Github Link': ['https://github.com/badr1002'], 'linkedin': ['linkedin.com/in/badr-helal-7308111a9/'], 'Facebook Link': None, 'skills': ['Flask', 'Writing', 'computer science', 'HTML', 'algorithms', 'SQL', 'html', 'JS', 'JavaScript', 'Postgresql', 'Website', 'Technical', 'api', 'sql', 'Apis', 'css', 'cloud', 'Github', 'Adobe', 'mobile', 'Coding', 'Security', 'Mobile', 'Programming', 'English', 'JSON', 'Computer Software', 'API', 'Testing', 'python', 'js', 'CSS', 'Information Technology', 'aws', 'Email', 'APIs'], 'Education': {'Start Year': '2018', 'End Year': '2022', 'Degree': 'Bachelor’s Degree in computer science', 'University': 'El Shorouk Academy (SHA), Egypt', 'Grade': 'Good', 'Studied Subjects': 'Program Languages and Skills in Programing Field.'}}\n"
     ]
    }
   ],
   "source": [
    "print(parsed_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "5d8f7ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Name\": \"Badr Helal\",\n",
      "    \"E-mail\": \"baderhelal567@gmail.com\",\n",
      "    \"Phone number\": \"201553060232\",\n",
      "    \"Job Title\": \"Full Stack Developer\",\n",
      "    \"Address\": \"New Cairo\",\n",
      "    \"Birthday\": \"1st of July 2000\",\n",
      "    \"Github Link\": [\n",
      "        \"https://github.com/badr1002\"\n",
      "    ],\n",
      "    \"linkedin\": [\n",
      "        \"linkedin.com/in/badr-helal-7308111a9/\"\n",
      "    ],\n",
      "    \"Facebook Link\": null,\n",
      "    \"skills\": [\n",
      "        \"Flask\",\n",
      "        \"Writing\",\n",
      "        \"computer science\",\n",
      "        \"HTML\",\n",
      "        \"algorithms\",\n",
      "        \"SQL\",\n",
      "        \"html\",\n",
      "        \"JS\",\n",
      "        \"JavaScript\",\n",
      "        \"Postgresql\",\n",
      "        \"Website\",\n",
      "        \"Technical\",\n",
      "        \"api\",\n",
      "        \"sql\",\n",
      "        \"Apis\",\n",
      "        \"css\",\n",
      "        \"cloud\",\n",
      "        \"Github\",\n",
      "        \"Adobe\",\n",
      "        \"mobile\",\n",
      "        \"Coding\",\n",
      "        \"Security\",\n",
      "        \"Mobile\",\n",
      "        \"Programming\",\n",
      "        \"English\",\n",
      "        \"JSON\",\n",
      "        \"Computer Software\",\n",
      "        \"API\",\n",
      "        \"Testing\",\n",
      "        \"python\",\n",
      "        \"js\",\n",
      "        \"CSS\",\n",
      "        \"Information Technology\",\n",
      "        \"aws\",\n",
      "        \"Email\",\n",
      "        \"APIs\"\n",
      "    ],\n",
      "    \"Education\": {\n",
      "        \"Start Year\": \"2018\",\n",
      "        \"End Year\": \"2022\",\n",
      "        \"Degree\": \"Bachelor\\u2019s Degree in computer science\",\n",
      "        \"University\": \"El Shorouk Academy (SHA), Egypt\",\n",
      "        \"Grade\": \"Good\",\n",
      "        \"Studied Subjects\": \"Program Languages and Skills in Programing Field.\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"SignUp.json\", \"w\") as outfile:\n",
    "    json.dump(parsed_content, outfile)\n",
    "    \n",
    "    \n",
    "    a_file = open(\"SignUp.json\", \"r\")\n",
    "a_json = json.load(a_file)\n",
    "pretty_json = json.dumps(a_json, indent=4)\n",
    "a_file.close()\n",
    "print(pretty_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8856f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f708dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684cee05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07c8d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
